<tool id="cardinal_classification" name="MSI classification" version="@TOOL_VERSION@+galaxy@VERSION_SUFFIX@" profile="22.05">
    <description>spatial classification of mass spectrometry imaging data</description>
    <macros>
        <import>macros.xml</import>
    </macros>
    <expand macro="requirements"/>
    <command detect_errors="exit_code">
        <![CDATA[

        @INPUT_LINKING@
        cat '${MSI_segmentation}' &&
        Rscript '${MSI_segmentation}'

    ]]>
    </command>
    <configfiles>
        <configfile name="MSI_segmentation"><![CDATA[


################################# load libraries and read file #########################

library(Cardinal)
library(gridExtra)
library(ggplot2)
library(scales)
library(tibble)
library(tidyr)
library(matter)



@READING_MSIDATA@


msidata = as(msidata, "MSImagingExperiment")

## remove duplicated coordinates
msidata <- msidata[,!duplicated(coord(msidata))]

@DATA_PROPERTIES_INRAM@


######################################## PDF ###################################
################################################################################
################################################################################

Title = "Prediction"

#if str( $type_cond.type_method) == "training":

        Title = "$type_cond.method_cond.class_method"
#end if

pdf("classificationpdf.pdf", fonts = "Times", pointsize = 12)
plot(0,type='n',axes=FALSE,ann=FALSE)


title(main=paste0(Title," for file: \n\n", "$infile.display_name"))


##################### I) numbers and control plots #############################
################################################################################

## table with values
grid.table(property_df, rows= NULL)

int_matrix = as.matrix(spectra(msidata))
NAcount = sum(is.na(int_matrix))


if (npeaks > 0 && NAcount==0){

    opar <- par()

    ######################## II) Training #######################################
    #############################################################################
    #if str( $type_cond.type_method) == "training":
        print("training")

        ## load y response (will be needed in every training scenario)

        y_tabular = read.delim("$type_cond.annotation_file", header = $type_cond.tabular_header, stringsAsFactors = FALSE)

        #if str($type_cond.column_fold) == "None":
        y_input = y_tabular[,c($type_cond.column_x, $type_cond.column_y, $type_cond.column_response)]
        #else
        y_input = y_tabular[,c($type_cond.column_x, $type_cond.column_y, $type_cond.column_response, $type_cond.column_fold)]
        #end if
        colnames(y_input)[1:2] = c("x", "y")

        ## merge with coordinate information of msidata
        msidata_coordinates = cbind(coord(msidata)[,1:2], c(1:ncol(msidata)))
        colnames(msidata_coordinates)[3] = "pixel_index"
        merged_response = as.data.frame(merge(msidata_coordinates, y_input, by=c("x", "y"), all.x=TRUE))
        merged_response[is.na(merged_response)] = "NA"
        merged_response = merged_response[order(merged_response\$pixel_index),]
        condition = as.factor(merged_response[,4])
        y_vector = condition

        ## colours selection:

	    #if str($colour_conditional.colour_type) == "manual_colour"
	        #set $color_string = ','.join(['"%s"' % $color.annotation_color for $color in $colour_conditional.colours])
	        colourvector = c($color_string)

	    #elif str($colour_conditional.colour_type) == "colourpalette"
	        number_levels = (length(levels(condition)))
	        colourvector = noquote($colour_conditional.palettes)(number_levels)

	    #end if


        ## plot of y vector

        position_df = as.data.frame(cbind(coord(msidata)[,1:2], condition))

        y_plot = ggplot(position_df, aes(x=x, y=y, fill=condition))+
           geom_tile() +
           coord_fixed()+
           ggtitle("Distribution of the conditions")+
		   theme_bw()+
           theme(
	       plot.background = element_blank(),
	       panel.grid.major = element_blank(),
	       panel.grid.minor = element_blank())+
           theme(text=element_text(family="ArialMT", face="bold", size=15))+
           theme(legend.position="bottom",legend.direction="vertical")+
           guides(fill=guide_legend(ncol=4,byrow=TRUE))+
           scale_discrete_manual(aesthetics = c("colour", "fill"), values = colourvector)
        coord_labels = aggregate(cbind(x,y)~condition, data=position_df, mean, na.rm=TRUE, na.action="na.pass")
        ##coord_labels\$file_number = gsub( "_.*$", "", coord_labels\$condition)
        print(y_plot)

        ## plot of folds

        #if str($type_cond.column_fold) != "None":
            fold_vector = as.factor(merged_response[,5])

            position_df = as.data.frame(cbind(coord(msidata)[,1:2], fold_vector))
            fold_plot = ggplot(position_df, aes(x=x, y=y, fill=fold_vector))+
               geom_tile() +
               coord_fixed()+
               ggtitle("Distribution of the fold variable")+
	           theme_bw()+
               theme(
	           plot.background = element_blank(),
	           panel.grid.major = element_blank(),
	           panel.grid.minor = element_blank())+
               theme(text=element_text(family="ArialMT", face="bold", size=15))+
               theme(legend.position="bottom",legend.direction="vertical")+
               guides(fill=guide_legend(ncol=4,byrow=TRUE))
            coord_labels = aggregate(cbind(x,y)~fold_vector, data=position_df, mean, na.rm=TRUE, na.action="na.pass")
            ##coord_labels\$file_number = gsub( "_.*$", "", coord_labels\$fold_vector)
            print(fold_plot)

        #end if

        ######################## PLS #############################
        #if str( $type_cond.method_cond.class_method) == "PLS":
            print("PLS")

            ######################## PLS - CV #############################
            #if str( $type_cond.method_cond.analysis_cond.PLS_method) == "cvapply":
                print("PLS cv")

                ## set variables for components and number of response groups
                components = c($type_cond.method_cond.analysis_cond.plscv_comp)
                number_groups = length(levels(y_vector))

                ## PLS-cvApply:
                cv_pls <- crossValidate(PLS, x = msidata, y = y_vector,  folds = fold_vector, ncomp = components)
                print("crossvalidation for pls done")


                ## remove msidata to clean up RAM space
                rm(msidata)
                gc()


                ### New table for precision and recall of cv results ###

                prec_rec_table = as.data.frame(cv_pls@model[["average"]])
                prec_rec_table <- prec_rec_table %>%
                                    rownames_to_column(var = "ncomp")

                prec_rec_table\$ncomp <- as.numeric(sub("ncomp=", "", prec_rec_table\$ncomp))

                colnames(prec_rec_table) = c("ncomp", "Recall", "Precision")

                plot(0,type='n',axes=FALSE,ann=FALSE)
                title(main=paste0("Average Precision and Recall"))

                prec_rec_round <- round(prec_rec_table, digits=4)

                ## 20 rows fits in one page:
                if (nrow(prec_rec_round)<=20){
                    grid.table(prec_rec_round, rows= NULL)
                }else{
                    grid.table(prec_rec_round[1:20,], rows= NULL)
                    mincount = 21
                    maxcount = 40
                    for (count20 in 1:(ceiling(nrow(prec_rec_round)/20)-1)){
                        plot(0,type='n',axes=FALSE,ann=FALSE)
                        if (maxcount <= nrow(prec_rec_round)){
                            grid.table(prec_rec_round[mincount:maxcount,], rows= NULL)
                            mincount = mincount+20
                            maxcount = maxcount+20
                        }else{### stop last page with last sample otherwise NA in table
                            grid.table(prec_rec_round[mincount:nrow(prec_rec_round),], rows= NULL)}
                    }
                }

                prec_rec_long <- prec_rec_table %>%
                  pivot_longer(cols = c(Recall, Precision), names_to = "Metric", values_to = "Score")

                ###plot Precision and recall over components
                components_plot = ggplot(prec_rec_long, aes(x = ncomp, y = Score, color = Metric)) +
                  geom_point(size = 3) +
                  geom_line() +
                  scale_color_manual(values = c("#FFBA0A", "#0082CC")) +
                  labs(title = "Precision and Recall over Components",
                       x = "Number of Components (ncomp)",
                       y = "Score")+
                  theme_bw()

                print(components_plot)

                ### New plot for: Recall over precision ###

                prec_rec_plot = ggplot(prec_rec_table, aes(x = Precision, y = Recall, label = ncomp)) +
                  geom_point(size = 3, color = "#0082CC") +
                  geom_text(vjust = -1, size = 3) +
                  labs(title = "Precision vs. Recall",
                       x = "Precision",
                       y = "Recall") +
                  theme_minimal() +
                  theme(text = element_text(size = 14))

                print(prec_rec_plot)

                for (i in components) {
                print(image(cv_pls, i = i, type = "response", layout = c(1,1)))
                            }


                ## optional output as .RData
                #if $output_rdata:
                    save(cv_pls, file="$classification_rdata")
                #end if


            ######################## PLS - analysis ###########################
            #elif str( $type_cond.method_cond.analysis_cond.PLS_method) == "PLS_analysis":
                print("PLS analysis")

                ## set variables for components and number of response groups
                component = c($type_cond.method_cond.analysis_cond.pls_comp)
                number_groups = length(levels(y_vector))

                ### stop if multiple values for PLS components are selected what sets component to 0
                tryCatch(
                        {

                        if (component==0)
                            {
                            stop(call.=FALSE)
                            }
                        },
                        error=function(cond) {
                        ## in case user used multiple inputs for component - this is only possible in cv apply
                            message("Error during PLS training")
                            message("Possible problems: Multiple values for component were selected - this is only possible in cvapply but not for PLS analysis or component was set to 0 but minimum for component is 1)")
                            stop(call.=FALSE)
                        }
                    )

                ### pls analysis
                msidata.pls <- PLS(msidata, y = y_vector, ncomp = component,
                                        method=$type_cond.method_cond.analysis_cond.pls_alg,
                                        scale=$type_cond.method_cond.analysis_cond.pls_scale,
                                        center=$type_cond.method_cond.analysis_cond.pls_center)


                ## remove msidata to clean up RAM space
                rm(msidata)
                gc()


                ### fit pls model with training data
                fit.pls = Cardinal::fitted(msidata.pls, type="class")

                ### calculate precision and recall values
                prec_rec_table = matter::predscore(x = fit.pls, ref = y_vector)
                prec_rec_table = as.data.frame(prec_rec_table)
                prec_rec_table <- prec_rec_table %>%
                                     rownames_to_column(var = "Condition")

                plot(0,type='n',axes=FALSE,ann=FALSE)
                title(main=paste0("PLS Precision and Recall on Training Set"))
                grid.table(prec_rec_table, rows= NULL)


                ### pixel table
                pixel_table = as.data.frame(msidata.pls@pixelData)
                pixel_table = cbind(pixel_names = paste0("xy_", pixel_table\$x, "_", pixel_table\$y), pixel_table)


                ### new code for correctness calculation and plot
                correctness_table = data.frame(cbind(pixel_names = paste0("xy_", pixel_table\$x, "_", pixel_table\$y)), pixel_table\$x, pixel_table\$y, y_vector, fit.pls)
                colnames(correctness_table) = c("pixel_names", "x", "y", "true_class", "predicted_class")
                correctness_table\$correct <- ifelse(correctness_table\$predicted_class==correctness_table\$true_class, T, F)
                correctness = round(sum(correctness_table\$correct)/length(correctness_table\$correct)*100,2)

                ### color selection for correctness_plot
                #if str($correctness_plot_condition.correctness_plot_color) == "default"
                    true_col = c("#f28e2b")
                    false_col = c("#4e79a7")

                #elif str($correctness_plot_condition.correctness_plot_color) == "custom"
                    true_col = c("$true_color")
                    false_col = c("$false_color")

                #end if


                ## correctness plot
	            correctness_plot = ggplot(correctness_table, aes(x=x, y=y, fill=correct))+
                       geom_tile() +
                       coord_fixed()+
                       ggtitle(paste0("Correctness of classification: ", correctness, " %"))+
                       scale_fill_manual(values = c("TRUE" = true_col, "FALSE" = false_col))+
		               theme_bw()+
                       theme(
    		           plot.background = element_blank(),
   		               panel.grid.major = element_blank(),
  		               panel.grid.minor = element_blank())+
                       theme(text=element_text(family="ArialMT", face="bold", size=15))+
                       theme(legend.position="bottom",legend.direction="vertical")+
                       guides(fill=guide_legend(ncol=2,byrow=TRUE))
                coord_labels = aggregate(cbind(x,y)~correct, data=correctness_table, mean, na.rm=TRUE, na.action="na.pass")


                ### image with predicted classes
                prediction_plot = ggplot(correctness_table, aes(x=x, y=y, fill=predicted_class))+
                       geom_tile() +
                       coord_fixed()+
                       ggtitle("Predicted condition for each pixel")+
			        theme_bw()+
		            theme(
		            plot.background = element_blank(),
		            panel.grid.major = element_blank(),
		            panel.grid.minor = element_blank())+
                       theme(text=element_text(family="ArialMT", face="bold", size=15))+
                       theme(legend.position="bottom",legend.direction="vertical")+
                       guides(fill=guide_legend(ncol=4,byrow=TRUE))+
                       scale_discrete_manual(aesthetics = c("colour", "fill"), values = colourvector)
                coord_labels = aggregate(cbind(x,y)~predicted_class, data=correctness_table, mean, na.rm=TRUE, na.action="na.pass")

                ### print plots in following order:
                print(prediction_plot)
                print(correctness_plot)


                ### explained cumulative variance
                expl_cvar <- as.data.frame(msidata.pls@model[["cvar"]])
                expl_cvar <- round(expl_cvar, digits=3)
                expl_cvar <- expl_cvar %>%
                                rownames_to_column(var = "ncomp")
                colnames(expl_cvar)[2] = "explained_cumulative_variance"

                plot(0,type='n',axes=FALSE,ann=FALSE)
                title(main=paste0("Explained Cumulative Variance"))

                ## 20 rows fits in one page:
                if (nrow(expl_cvar)<=20){
                    grid.table(expl_cvar, rows= NULL)
                }else{
                    grid.table(expl_cvar[1:20,], rows= NULL)
                    mincount = 21
                    maxcount = 40
                    for (count20 in 1:(ceiling(nrow(expl_cvar)/20)-1)){
                        plot(0,type='n',axes=FALSE,ann=FALSE)
                        if (maxcount <= nrow(expl_cvar)){
                            grid.table(expl_cvar[mincount:maxcount,], rows= NULL)
                            mincount = mincount+20
                            maxcount = maxcount+20
                        }else{### stop last page with last sample otherwise NA in table
                            grid.table(expl_cvar[mincount:nrow(expl_cvar),], rows= NULL)}
                    }
                }


                ### cardinal plots
                minimumy = min(coord(msidata.pls)[,2])
                maximumy = max(coord(msidata.pls)[,2])
                minimumx = min(coord(msidata.pls)[,1])
                maximumx = max(coord(msidata.pls)[,1])

                x_min <- floor(minimumx / 10) * 10
                y_min <- floor(minimumy / 10) * 10
                x_max <- ceiling(maximumx / 10) * 10
                y_max <- ceiling(maximumy / 10) * 10


                print(image(msidata.pls, type="response", layout=c(1,1), scale=TRUE, col=colourvector, ylim= c(y_max, y_min), xlim= c(x_min, x_max)))
                title(main = "PLS Response")

                print(image(msidata.pls, type="class", layout=c(1,1), scale=TRUE, col=colourvector, ylim= c(y_max, y_min), xlim= c(x_min, x_max)))
                title(main=paste0("PLS Class"))

                print(plot(msidata.pls, type="coefficients", linewidth=2, annPeaks="circle", col=colourvector))
                title(main=paste0("PLS coefficients per m/z"))

                print(plot(msidata.pls, type="scores", groups=msidata.pls\$class, color=colourvector, linewidth=2))
                title(main=paste0("PLS scores per m/z"))

                print(plot(msidata.pls, type="vip", annPeaks="circle", color=colourvector, linewidth=2))
                title(main=paste0("PLS vip per m/z"))


                ### pixel table output
                write.table(correctness_table, file="$pixeloutput", quote = FALSE, row.names = FALSE, col.names=TRUE, sep = "\t")

                ### topFeatures table output
                top_feat_table = as.data.frame(topFeatures(msidata.pls, n=$pls_toplabels))

                write.table(top_feat_table, file="$topfeatures", quote = FALSE, row.names = FALSE, col.names=TRUE, sep = "\t")

                ### scores table output
                scores_tab = data.frame(msidata.pls@model[["scores"]])
                scores_tab <- scores_tab %>%
                                rownames_to_column(var = "Spectrum")

                write.table(scores_tab, file="$scoresoutput", quote = FALSE, row.names = FALSE, col.names=TRUE, sep = "\t")

	            ### optional output as .RData
                #if $output_rdata:
                    save(msidata.pls, file="$classification_rdata")
                #end if

            #end if

        ######################## OPLS #############################
        #elif str( $type_cond.method_cond.class_method) == "OPLS":
            print("OPLS")

            ######################## OPLS -CV #############################
            #if str( $type_cond.method_cond.opls_analysis_cond.opls_method) == "opls_cvapply":
                print("OPLS cv")

                ## set variables for components and number of response groups
                components = c($type_cond.method_cond.opls_analysis_cond.opls_cvcomp)
                number_groups = length(levels(y_vector))

                ## OPLS-cvApply:
                cv_opls <- crossValidate(OPLS, x = msidata, y = y_vector,  folds = fold_vector, ncomp = components)
                print("crossvalidation for opls done")


                ## remove msidata to clean up RAM space
                rm(msidata)
                gc()


                ### New table for precision and recall of cv results ###
                prec_rec_table = as.data.frame(cv_opls@model[["average"]])
                prec_rec_table <- prec_rec_table %>%
                                    rownames_to_column(var = "ncomp")

                prec_rec_table\$ncomp <- as.numeric(sub("ncomp=", "", prec_rec_table\$ncomp))

                colnames(prec_rec_table) = c("ncomp", "Recall", "Precision")

                plot(0,type='n',axes=FALSE,ann=FALSE)
                title(main=paste0("Average Precision and Recall"))

                prec_rec_round <- round(prec_rec_table, digits=4)

                ## 20 rows fits in one page:
                if (nrow(prec_rec_round)<=20){
                    grid.table(prec_rec_round, rows= NULL)
                }else{
                    grid.table(prec_rec_round[1:20,], rows= NULL)
                    mincount = 21
                    maxcount = 40
                    for (count20 in 1:(ceiling(nrow(prec_rec_round)/20)-1)){
                        plot(0,type='n',axes=FALSE,ann=FALSE)
                        if (maxcount <= nrow(prec_rec_round)){
                            grid.table(prec_rec_round[mincount:maxcount,], rows= NULL)
                            mincount = mincount+20
                            maxcount = maxcount+20
                        }else{### stop last page with last sample otherwise NA in table
                            grid.table(prec_rec_round[mincount:nrow(prec_rec_round),], rows= NULL)}
                    }
                }

                prec_rec_long <- prec_rec_table %>%
                  pivot_longer(cols = c(Recall, Precision), names_to = "Metric", values_to = "Score")

                ###plot Precision and recall over components
                components_plot = ggplot(prec_rec_long, aes(x = ncomp, y = Score, color = Metric)) +
                  geom_point(size = 3) +
                  geom_line() +
                  scale_color_manual(values = c("#FFBA0A", "#0082CC")) +
                  labs(title = "Precision and Recall over Components",
                       x = "Number of Components (ncomp)",
                       y = "Score")+
                  theme_bw()

                print(components_plot)

                ### New plot for: Recall over precision ###

                prec_rec_plot = ggplot(prec_rec_table, aes(x = Precision, y = Recall, label = ncomp)) +
                  geom_point(size = 3, color = "#0082CC") +
                  geom_text(vjust = -1, size = 3) +
                  labs(title = "Precision vs. Recall",
                       x = "Precision",
                       y = "Recall") +
                  theme_minimal() +
                  theme(text = element_text(size = 14))

                print(prec_rec_plot)

                for (i in components) {
                print(image(cv_opls, i = i, type = "response", layout = c(1,1)))
                            }


                ## optional output as .RData
                #if $output_rdata:
                    save(cv_opls, file="$classification_rdata")
                #end if


            ######################## OPLS -analysis ###########################
            #elif str( $type_cond.method_cond.opls_analysis_cond.opls_method) == "opls_analysis":
                print("OPLS analysis")

                ## set variables for components and number of response groups
                component = c($type_cond.method_cond.opls_analysis_cond.opls_comp)
                number_groups = length(levels(y_vector))

                ### stop if multiple values for OPLS components are selected what sets component to 0
                tryCatch(
                        {

                        if (component==0)
                            {
                            stop(call.=FALSE)
                            }
                        },
                        error=function(cond) {
                        ## in case user used multiple inputs for component - this is only possible in cv apply
                            message("Error during OPLS training")
                            message("Possible problems: Multiple values for component were selected - this is only possible in cvapply but not for PLS analysis or component was set to 0 but minimum for component is 1)")
                            stop(call.=FALSE)
                        }
                    )

                ### opls analysis
                msidata.opls <- OPLS(msidata, y = y_vector, ncomp = component,
                                        scale=$type_cond.method_cond.opls_analysis_cond.opls_scale,
                                        center=$type_cond.method_cond.opls_analysis_cond.opls_center)


                ## remove msidata to clean up RAM space
                rm(msidata)
                gc()


                ### fit opls model with training data
                fit.opls = Cardinal::fitted(msidata.opls, type="class")

                ### calculate precision and recall values
                prec_rec_table = matter::predscore(x = fit.opls, ref = y_vector)
                prec_rec_table = as.data.frame(prec_rec_table)
                prec_rec_table <- prec_rec_table %>%
                                     rownames_to_column(var = "Condition")

                plot(0,type='n',axes=FALSE,ann=FALSE)
                title(main=paste0("OPLS Precision and Recall on Training Set"))
                grid.table(prec_rec_table, rows= NULL)


                ### pixel table
                pixel_table = as.data.frame(msidata.opls@pixelData)
                pixel_table = cbind(pixel_names = paste0("xy_", pixel_table\$x, "_", pixel_table\$y), pixel_table)


                ### new code for correctness calculation and plot
                correctness_table = data.frame(cbind(pixel_names = paste0("xy_", pixel_table\$x, "_", pixel_table\$y)), pixel_table\$x, pixel_table\$y, y_vector, fit.opls)
                colnames(correctness_table) = c("pixel_names", "x", "y", "true_class", "predicted_class")
                correctness_table\$correct <- ifelse(correctness_table\$predicted_class==correctness_table\$true_class, T, F)
                correctness = round(sum(correctness_table\$correct)/length(correctness_table\$correct)*100,2)

                ### color selection for correctness_plot
                #if str($correctness_plot_condition.correctness_plot_color) == "default"
                    true_col = c("#f28e2b")
                    false_col = c("#4e79a7")

                #elif str($correctness_plot_condition.correctness_plot_color) == "custom"
                    true_col = c("$true_color")
                    false_col = c("$false_color")

                #end if

                ## correctness plot
	            correctness_plot = ggplot(correctness_table, aes(x=x, y=y, fill=correct))+
                       geom_tile() +
                       coord_fixed()+
                       ggtitle(paste0("Correctness of classification: ", correctness, " %"))+
                       scale_fill_manual(values = c("TRUE" = true_col, "FALSE" = false_col))+
		               theme_bw()+
                       theme(
    		           plot.background = element_blank(),
   		               panel.grid.major = element_blank(),
  		               panel.grid.minor = element_blank())+
                       theme(text=element_text(family="ArialMT", face="bold", size=15))+
                       theme(legend.position="bottom",legend.direction="vertical")+
                       guides(fill=guide_legend(ncol=2,byrow=TRUE))
                coord_labels = aggregate(cbind(x,y)~correct, data=correctness_table, mean, na.rm=TRUE, na.action="na.pass")


                ### image with predicted classes
                prediction_plot = ggplot(correctness_table, aes(x=x, y=y, fill=predicted_class))+
                       geom_tile() +
                       coord_fixed()+
                       ggtitle("Predicted condition for each pixel")+
			        theme_bw()+
		            theme(
		            plot.background = element_blank(),
		            panel.grid.major = element_blank(),
		            panel.grid.minor = element_blank())+
                       theme(text=element_text(family="ArialMT", face="bold", size=15))+
                       theme(legend.position="bottom",legend.direction="vertical")+
                       guides(fill=guide_legend(ncol=4,byrow=TRUE))+
                       scale_discrete_manual(aesthetics = c("colour", "fill"), values = colourvector)
                coord_labels = aggregate(cbind(x,y)~predicted_class, data=correctness_table, mean, na.rm=TRUE, na.action="na.pass")

                ### print plots in following order:
                print(prediction_plot)
                print(correctness_plot)


                ### explained cumulative variance
                opls_ratio <- as.data.frame(msidata.opls@model[["ratio"]])
                opls_ratio <- round(opls_ratio, digits=3)
                opls_ratio <- opls_ratio %>%
                                rownames_to_column(var = "ncomp")
                colnames(opls_ratio)[2] = "ratio"

                plot(0,type='n',axes=FALSE,ann=FALSE)
                title(main=paste0("OPLS ratio"))

                ## 20 rows fits in one page:
                if (nrow(opls_ratio)<=20){
                    grid.table(opls_ratio, rows= NULL)
                }else{
                    grid.table(opls_ratio[1:20,], rows= NULL)
                    mincount = 21
                    maxcount = 40
                    for (count20 in 1:(ceiling(nrow(opls_ratio)/20)-1)){
                        plot(0,type='n',axes=FALSE,ann=FALSE)
                        if (maxcount <= nrow(opls_ratio)){
                            grid.table(opls_ratio[mincount:maxcount,], rows= NULL)
                            mincount = mincount+20
                            maxcount = maxcount+20
                        }else{### stop last page with last sample otherwise NA in table
                            grid.table(expl_cvar[mincount:nrow(opls_ratio),], rows= NULL)}
                    }
                }


                ### cardinal plots
                minimumy = min(coord(msidata.opls)[,2])
                maximumy = max(coord(msidata.opls)[,2])
                minimumx = min(coord(msidata.opls)[,1])
                maximumx = max(coord(msidata.opls)[,1])

                x_min <- floor(minimumx / 10) * 10
                y_min <- floor(minimumy / 10) * 10
                x_max <- ceiling(maximumx / 10) * 10
                y_max <- ceiling(maximumy / 10) * 10


                print(image(msidata.opls, type="response", layout=c(1,1), scale=TRUE, col=colourvector, ylim= c(y_max, y_min), xlim= c(x_min, x_max)))
                title(main = "OPLS Response")

                print(image(msidata.opls, type="class", layout=c(1,1), scale=TRUE, col=colourvector, ylim= c(y_max, y_min), xlim= c(x_min, x_max)))
                title(main=paste0("OPLS Class"))

                print(plot(msidata.opls, type="coefficients", linewidth=2, annPeaks="circle", col=colourvector))
                title(main=paste0("OPLS coefficients per m/z"))

                print(plot(msidata.opls, type="scores", groups=msidata.opls\$class, color=colourvector, linewidth=2))
                title(main=paste0("OPLS scores per m/z"))


                ### pixel table output
                write.table(correctness_table, file="$pixeloutput", quote = FALSE, row.names = FALSE, col.names=TRUE, sep = "\t")

                ### topFeatures table output
                top_feat_table = as.data.frame(topFeatures(msidata.opls, n=$opls_toplabels))

                write.table(top_feat_table, file="$topfeatures", quote = FALSE, row.names = FALSE, col.names=TRUE, sep = "\t")

                ### scores table output
                scores_tab = data.frame(msidata.opls@model[["scores"]])
                scores_tab <- scores_tab %>%
                                rownames_to_column(var = "Spetrum")

                write.table(scores_tab, file="$scoresoutput", quote = FALSE, row.names = FALSE, col.names=TRUE, sep = "\t")

	            ### optional output as .RData
                #if $output_rdata:
                    save(msidata.opls, file="$classification_rdata")
                #end if

            #end if


        ######################## SSC #############################
        #elif str( $type_cond.method_cond.class_method) == "spatialShrunkenCentroids":
            print("SSC")

            ######################## SSC - CV #############################
            #if str( $type_cond.method_cond.ssc_analysis_cond.ssc_method) == "ssc_cvapply":
                print("SSC cv")

                ## set variables for components and number of response groups
                number_groups = length(levels(y_vector))

                ## SSC-cvApply:
                cv_ssc <- crossValidate(spatialShrunkenCentroids, x=msidata, y = y_vector, folds = fold_vector, r = c($type_cond.method_cond.ssc_r), s = c($type_cond.method_cond.ssc_s))



                ## remove msidata to clean up RAM space
                rm(msidata)
                gc()


                ### New table for precision and recall of cv results ###
                prec_rec_table = as.data.frame(cv_ssc@model[["average"]])
                prec_rec_round <- round(prec_rec_table, digits=4)

                prec_rec_round <- prec_rec_round %>%
                                      rownames_to_column(var = "model")
                colnames(prec_rec_round) = c("model", "Recall", "Precision")

                ### split r and s values in individual columns
                prec_rec_round\$r <- gsub("r=", "", sapply(strsplit(prec_rec_round\$model, ","), `[`, 1))
                prec_rec_round\$s <- as.numeric(gsub("s=", "", sapply(strsplit(prec_rec_round\$model, ","), "[", 2)))

                # Remove the original 'model' column
                prec_rec_round\$model <- NULL

                plot(0,type='n',axes=FALSE,ann=FALSE)
                title(main=paste0("Average Precision and Recall"))

                ## 20 rows fits in one page:
                if (nrow(prec_rec_round)<=20){
                  grid.table(prec_rec_round, rows= NULL)
                }else{
                  grid.table(prec_rec_round[1:20,], rows= NULL)
                  mincount = 21
                  maxcount = 40
                  for (count20 in 1:(ceiling(nrow(prec_rec_round)/20)-1)){
                    plot(0,type='n',axes=FALSE,ann=FALSE)
                    if (maxcount <= nrow(prec_rec_round)){
                      grid.table(prec_rec_round[mincount:maxcount,], rows= NULL)
                      mincount = mincount+20
                      maxcount = maxcount+20
                    }else{### stop last page with last sample otherwise NA in table
                      grid.table(prec_rec_round[mincount:nrow(prec_rec_round),], rows= NULL)}
                  }
                }

                prec_rec_long <- prec_rec_round %>%
                  pivot_longer(cols = c(Recall, Precision), names_to = "Metric", values_to = "Score")

                ###plot Precision and recall over components
                centroids_plot = ggplot(prec_rec_long , aes(x = s, y = Score, color = r, shape = Metric)) +
                  geom_point(size = 3) +
                  geom_line() +
                  labs(title = "Precision and Recall over Centroids",
                       x = "s",
                       y = "Score")+
                  theme_bw()

                print(centroids_plot)

                ### New plot for: Recall over precision ###

                prec_rec_plot = ggplot(prec_rec_round, aes(x = Precision, y = Recall, label = r, color = s)) +
                  geom_point(size = 3) +            ###color = "#0082CC"
                  geom_text(vjust = -1, size = 3) +
                  labs(title = "Precision vs. Recall",
                       x = "Precision",
                       y = "Recall") +
                  theme_minimal() +
                  theme(text = element_text(size = 14))

                print(prec_rec_plot)


                ## new code to extract r and s values with highest precision
                max_precision_index <- which.max(prec_rec_round\$Precision)

                print(max_precision_index)

                ## extract the corresponding values of "r" and "s"
                highest_accuracy_r <- prec_rec_round\$r[max_precision_index]
                highest_accuracy_s <- prec_rec_round\$s[max_precision_index]

		        #if $type_cond.method_cond.ssc_analysis_cond.write_best_params:
                	write.table(highest_accuracy_r, file="$best_r", quote = FALSE, row.names = FALSE, col.names=FALSE, sep = "\t")
                	write.table(highest_accuracy_s, file="$best_s", quote = FALSE, row.names = FALSE, col.names=FALSE, sep = "\t")
                #end if


                ## optional output as .RData
                #if $output_rdata:
                    save(cv_ssc, file="$classification_rdata")
                #end if

            ######################## SSC -analysis ###########################
            #elif str( $type_cond.method_cond.ssc_analysis_cond.ssc_method) == "ssc_analysis":
                print("SSC analysis")

                ## set variables for components and number of response groups
                number_groups = length(levels(y_vector))

                ## SSC analysis and plot
                msidata.ssc <- spatialShrunkenCentroids(msidata, y = y_vector, r = $type_cond.method_cond.ssc_r, s = $type_cond.method_cond.ssc_s, weights = "$type_cond.method_cond.ssc_kernel_method")


                ### stop if multiple values for r and s were used as input
                tryCatch(
                        {

                        if (length(msidata.ssc@model[["s"]])>1 || length(msidata.ssc@model[["r"]]) > 1)
                            {
                            stop(call.=FALSE)
                            }
                        },
                        error=function(cond) {
                        ## in case user used multiple inputs for r or s stop - this is only possible in cv apply
                            message("Error during SSC training")
                            message("Possible problem: multiple values for r or s selected - this is only possible in cvapply but not for spatial shrunken centroid analysis)")
                            stop(call.=FALSE)
                        }
                    )



                ## remove msidata to clean up RAM space
                rm(msidata)
                gc()



                ### fit opls model with training data
                fit.ssc = Cardinal::fitted(msidata.ssc, type="class")

                ### calculate precision and recall values
                prec_rec_table = matter::predscore(x = fit.ssc, ref = y_vector)
                prec_rec_table = as.data.frame(prec_rec_table)
                prec_rec_table <- prec_rec_table %>%
                                     rownames_to_column(var = "Condition")

                plot(0,type='n',axes=FALSE,ann=FALSE)
                title(main=paste0("SSC Precision and Recall on Training Set"))
                grid.table(prec_rec_table, rows= NULL)


                ### pixel table
                pixel_table = as.data.frame(msidata.ssc@pixelData)
                pixel_table = cbind(pixel_names = paste0("xy_", pixel_table\$x, "_", pixel_table\$y), pixel_table)


                ### new code for correctness calculation and plot
                correctness_table = data.frame(cbind(pixel_names = paste0("xy_", pixel_table\$x, "_", pixel_table\$y)), pixel_table\$x, pixel_table\$y, y_vector, fit.ssc)
                colnames(correctness_table) = c("pixel_names", "x", "y", "true_class", "predicted_class")
                correctness_table\$correct <- ifelse(correctness_table\$predicted_class==correctness_table\$true_class, T, F)
                correctness = round(sum(correctness_table\$correct)/length(correctness_table\$correct)*100,2)

                ### color selection for correctness_plot
                #if str($correctness_plot_condition.correctness_plot_color) == "default"
                    true_col = c("#f28e2b")
                    false_col = c("#4e79a7")

                #elif str($correctness_plot_condition.correctness_plot_color) == "custom"
                    true_col = c("$true_color")
                    false_col = c("$false_color")

                #end if

                ## correctness plot
	            correctness_plot = ggplot(correctness_table, aes(x=x, y=y, fill=correct))+
                       geom_tile() +
                       coord_fixed()+
                       ggtitle(paste0("Correctness of classification: ", correctness, " %"))+
                       scale_fill_manual(values = c("TRUE" = true_col, "FALSE" = false_col))+
		               theme_bw()+
                       theme(
    		           plot.background = element_blank(),
   		               panel.grid.major = element_blank(),
  		               panel.grid.minor = element_blank())+
                       theme(text=element_text(family="ArialMT", face="bold", size=15))+
                       theme(legend.position="bottom",legend.direction="vertical")+
                       guides(fill=guide_legend(ncol=2,byrow=TRUE))
                coord_labels = aggregate(cbind(x,y)~correct, data=correctness_table, mean, na.rm=TRUE, na.action="na.pass")


                ### image with predicted classes
                prediction_plot = ggplot(correctness_table, aes(x=x, y=y, fill=predicted_class))+
                       geom_tile() +
                       coord_fixed()+
                       ggtitle("Predicted condition for each pixel")+
			        theme_bw()+
		            theme(
		            plot.background = element_blank(),
		            panel.grid.major = element_blank(),
		            panel.grid.minor = element_blank())+
                       theme(text=element_text(family="ArialMT", face="bold", size=15))+
                       theme(legend.position="bottom",legend.direction="vertical")+
                       guides(fill=guide_legend(ncol=4,byrow=TRUE))+
                       scale_discrete_manual(aesthetics = c("colour", "fill"), values = colourvector)
                coord_labels = aggregate(cbind(x,y)~predicted_class, data=correctness_table, mean, na.rm=TRUE, na.action="na.pass")

                ### print plots in following order:
                print(prediction_plot)
                print(correctness_plot)


                ### cardinal plots

                minimumy = min(coord(msidata.ssc)[,2])
                maximumy = max(coord(msidata.ssc)[,2])
                minimumx = min(coord(msidata.ssc)[,1])
                maximumx = max(coord(msidata.ssc)[,1])

                x_min <- floor(minimumx / 10) * 10
                y_min <- floor(minimumy / 10) * 10
                x_max <- ceiling(maximumx / 10) * 10
                y_max <- ceiling(maximumy / 10) * 10


                print(image(msidata.ssc, type="probability", layout=c(1,1), scale=TRUE, col=colourvector, ylim= c(y_max, y_min), xlim= c(x_min, x_max)))
                title(main = "SSC Probability")

                print(image(msidata.ssc, type="class", layout=c(1,1), scale=TRUE, col=colourvector, ylim= c(y_max, y_min), xlim= c(x_min, x_max)))
                title(main=paste0("SSC Class"))

                print(plot(msidata.ssc, type="statistic", linewidth=2, annPeaks="circle", col=colourvector))
                title(main=paste0("SSC statistics per m/z"))

                print(plot(msidata.ssc, type="centers", groups=msidata.opls\$class, color=colourvector, linewidth=2))
                title(main=paste0("SSC centers per m/z"))


                ### pixel table output
                write.table(correctness_table, file="$pixeloutput", quote = FALSE, row.names = FALSE, col.names=TRUE, sep = "\t")

                ### topFeatures table output
                top_feat_table = as.data.frame(topFeatures(msidata.ssc, n=$ssc_toplabels))
                top_feat_table\$centers = round (top_feat_table\$centers, digits = 6)
                top_feat_table\$statistic = round (top_feat_table\$statistic, digits = 6)

                write.table(top_feat_table, file="$topfeatures", quote = FALSE, row.names = FALSE, col.names=TRUE, sep = "\t")

              ## optional output as .RData
                #if $output_rdata:
                    save(msidata.ssc, file="$classification_rdata")
                #end if
            #end if
        #end if



    ######################## II) Prediction #############################
    #############################################################################

    #elif str($type_cond.type_method) == "prediction":
        print("prediction")

        ## load classifier model
        training_data = loadRData("$type_cond.training_result")


        #if str($type_cond.new_y_values_cond.new_y_values) == "new_response":
            print("new response")

            new_y_tabular = read.delim("$type_cond.new_y_values_cond.new_response_file", header = $type_cond.new_y_values_cond.new_tabular_header, stringsAsFactors = FALSE)
            new_y_input = new_y_tabular[,c($type_cond.new_y_values_cond.column_new_x, $type_cond.new_y_values_cond.column_new_y, $type_cond.new_y_values_cond.column_new_response)]
            colnames(new_y_input) = c("x", "y", "true_class")

            ## merge with coordinate information of msidata
            msidata_coordinates = cbind(coord(msidata)[,1:2], c(1:ncol(msidata)))
            colnames(msidata_coordinates)= c("x", "y", "pixel_index")

            merged_response = as.data.frame(merge(msidata_coordinates, new_y_input, by=c("x", "y"), all.x=TRUE))
            merged_response[is.na(merged_response)] = "NA"
            merged_response = merged_response[order(merged_response\$pixel_index),]
            new_y_vector = as.factor(merged_response[,4])


            ## colours selection:
            number_levels = length(levels(new_y_vector))

            #if str($colour_conditional.colour_type) == "manual_colour"
            #set $color_string = ','.join(['"%s"' % $color.annotation_color for $color in $colour_conditional.colours])
                colourvector = c($color_string)

            #elif str($colour_conditional.colour_type) == "colourpalette"
            colourvector = noquote($colour_conditional.palettes)(number_levels)

            #end if


            ### plot of new y vector

            y_plot = ggplot(merged_response, aes(x=x, y=y, fill=true_class))+
               geom_tile() +
               coord_fixed()+
               ggtitle("Distribution of the conditions")+
               theme_bw()+
               theme(
               plot.background = element_blank(),
               panel.grid.major = element_blank(),
               panel.grid.minor = element_blank())+
               theme(text=element_text(family="ArialMT", face="bold", size=15))+
               theme(legend.position="bottom",legend.direction="vertical")+
               guides(fill=guide_legend(ncol=4,byrow=TRUE))+
               scale_discrete_manual(aesthetics = c("colour", "fill"), values = colourvector)
            coord_labels = aggregate(cbind(x,y)~true_class, data=merged_response, mean, na.rm=TRUE, na.action="na.pass")
            ##coord_labels\$file_number = gsub( "_.*$", "", coord_labels\$true_class)
            print(y_plot)

            ### prediction of response probability
            pred_response = predict(training_data, msidata, type="response")

            ### predicted classes for precision and recall
            predicted_class = predict(training_data, msidata, type="class")

            ### prediction table
            pred_response_table = cbind(coord(msidata), predicted_class, pred_response)

                        ### Precision and Recall table
            prec_rec_table = matter::predscore(x = predicted_class, ref = new_y_vector)
            prec_rec_table = as.data.frame(prec_rec_table)
            prec_rec_table <- prec_rec_table %>%
              rownames_to_column(var = "Condition")

	        plot(0,type='n',axes=FALSE,ann=FALSE)
	        title(main=paste0("Classification Precision and Recall on New MSI Data"))
            grid.table(prec_rec_table, rows= NULL)


            ### new code for correctness calculation and plot
            correctness_table = cbind(pred_response_table, new_y_vector)
            correctness_table\$correct <- ifelse(correctness_table\$predicted_class==correctness_table\$new_y_vector, T, F)
            correctness = round(sum(correctness_table\$correct)/length(correctness_table\$correct)*100,2)

            ### color selection for correctness_plot
            #if str($correctness_plot_condition.correctness_plot_color) == "default"
                true_col = c("#f28e2b")
                false_col = c("#4e79a7")

            #elif str($correctness_plot_condition.correctness_plot_color) == "custom"
                true_col = c("$true_color")
                false_col = c("$false_color")

            #end if

            ## correctness plot
            correctness_plot = ggplot(correctness_table, aes(x=x, y=y, fill=correct))+
                   geom_tile() +
                   coord_fixed()+
                   ggtitle(paste0("Correctness of classification: ", correctness, " %"))+
                   scale_fill_manual(values = c("TRUE" = true_col, "FALSE" = false_col))+
                   theme_bw()+
                   theme(
                   plot.background = element_blank(),
                   panel.grid.major = element_blank(),
                   panel.grid.minor = element_blank())+
                   theme(text=element_text(family="ArialMT", face="bold", size=15))+
                   theme(legend.position="bottom",legend.direction="vertical")+
                   guides(fill=guide_legend(ncol=2,byrow=TRUE))
            coord_labels = aggregate(cbind(x,y)~correct, data=correctness_table, mean, na.rm=TRUE, na.action="na.pass")


            ### image with predicted classes
            prediction_plot = ggplot(correctness_table, aes(x=x, y=y, fill=predicted_class))+
                   geom_tile() +
                   coord_fixed()+
                   ggtitle("Predicted condition for each pixel")+
                theme_bw()+
                theme(
                plot.background = element_blank(),
                panel.grid.major = element_blank(),
                panel.grid.minor = element_blank())+
                   theme(text=element_text(family="ArialMT", face="bold", size=15))+
                   theme(legend.position="bottom",legend.direction="vertical")+
                   guides(fill=guide_legend(ncol=4,byrow=TRUE))+
                   scale_discrete_manual(aesthetics = c("colour", "fill"), values = colourvector)
            coord_labels = aggregate(cbind(x,y)~predicted_class, data=correctness_table, mean, na.rm=TRUE, na.action="na.pass")

            ### print plots in following order:
            print(prediction_plot)
            print(correctness_plot)

            ### print correctness_table
            write.table(correctness_table, file="$pixeloutput", quote = FALSE, row.names = FALSE, col.names=TRUE, sep = "\t")


        ##else for prediction without a new annotation (no calculation of accuracy):
        #else

            ### prediction of response probability
            pred_response = predict(training_data, msidata, type="response")

            ### predicted classes for precision and recall
            predicted_class = predict(training_data, msidata, type="class")

            pred_response_table = cbind(coord(msidata), predicted_class, pred_response)

            ## colours selection:
            number_levels = length(levels(predicted_class))
            print(number_levels)

            #if str($colour_conditional.colour_type) == "manual_colour"
            #set $color_string = ','.join(['"%s"' % $color.annotation_color for $color in $colour_conditional.colours])
                colourvector = c($color_string)

            #elif str($colour_conditional.colour_type) == "colourpalette"
            colourvector = noquote($colour_conditional.palettes)(number_levels)

            #end if


            ### image with predicted classes
            prediction_plot = ggplot(pred_response_table, aes(x=x, y=y, fill=predicted_class))+
                   geom_tile() +
                   coord_fixed()+
                   ggtitle("Predicted condition for each pixel")+
                theme_bw()+
                theme(
                plot.background = element_blank(),
                panel.grid.major = element_blank(),
                panel.grid.minor = element_blank())+
                   theme(text=element_text(family="ArialMT", face="bold", size=15))+
                   theme(legend.position="bottom",legend.direction="vertical")+
                   guides(fill=guide_legend(ncol=4,byrow=TRUE))+
                   scale_discrete_manual(aesthetics = c("colour", "fill"), values = colourvector)
            coord_labels = aggregate(cbind(x,y)~predicted_class, data=pred_response_table, mean, na.rm=TRUE, na.action="na.pass")

            print(prediction_plot)

            ### write output with prediction results
            write.table(pred_response_table, file="$pixeloutput", quote = FALSE, row.names = FALSE, col.names=TRUE, sep = "\t")


        #end if

    #end if

    dev.off()

}else{
    plot.new()
    text(0.5, 0.5, "Inputfile has no intensities > 0  \n or contains NA values.", cex = 1.5)
    print("Inputfile has no intensities > 0 or contains NA values")
    dev.off()
}


    ]]></configfile>
    </configfiles>
    <inputs>
        <expand macro="reading_msidata"/>
        <conditional name="type_cond">
            <param name="type_method" type="select" label="Analysis step to perform">
                <option value="training" selected="True">training</option>
                <option value="prediction">prediction</option>
            </param>
            <when value="training">

                <param name="annotation_file" type="data" format="tabular" label="Load tabular file with pixel coordinates and their classes"
                help="Three or four columns: x values, y values, response values, optionally fold values"/>
                <param name="column_x" data_ref="annotation_file" label="Column with x values" type="data_column"/>
                <param name="column_y" data_ref="annotation_file" label="Column with y values" type="data_column"/>
                <param name="column_response" data_ref="annotation_file" label="Column with response (condition) values" type="data_column" help="This is the condition (pixel group) which will be classified"/>
                <param name="column_fold" data_ref="annotation_file" optional="True" label="Column with fold values - only neccessary for cvapply" type="data_column" help="Each fold must contain pixels of all response groups and is used for cross validation"/>
                <param name="tabular_header" type="boolean" label="Tabular files contain a header line" truevalue="TRUE" falsevalue="FALSE"/>

                <conditional name="method_cond">
                    <param name="class_method" type="select" label="Select the method for classification">
                        <option value="PLS" selected="True">PLS-DA</option>
                        <option value="OPLS">OPLS-DA</option>
                        <option value="spatialShrunkenCentroids">spatial shrunken centroids</option>
                    </param>
                    <when value="PLS">

                        <conditional name="analysis_cond">
                            <param name="PLS_method" type="select" label="Crossvalidation or analysis">
                                <option value="cvapply" selected="True">cvApply</option>
                                <option value="PLS_analysis">PLS-DA analysis</option>
                            </param>
                            <when value="cvapply">
                                <param name="plscv_comp" type="text" value="1:2"
                                       label="The number of PLS-DA components" help="For cvapply multiple values are allowed (e.g. 1,2,3 or 2:5). Mininum is 1.">
                                <expand macro="sanitizer_multiple_digits"/>
                                </param>
                            </when>
                            <when value="PLS_analysis">
                                <param name="pls_comp" type="integer" value="5"
                                       label="The optimal number of PLS-DA components as indicated by cross-validations (minimum is 1)" help="Run cvApply first to optain optimal number of PLS-DA components"/>
                                <param name="pls_scale" type="boolean" label="Data scaling" truevalue="TRUE" falsevalue="FALSE"/>
                                <param name="pls_center" type="boolean" label="Data centering" truevalue="TRUE" falsevalue="FALSE"/>
                                <param name="pls_alg" type="select" label="PLS method">
                                    <option value="pls_nipals" selected="True">nipals</option>
                                    <option value="pls_simpls">simpls</option>
                                    <option value="pls_kernel1">kernel1</option>
                                    <option value="pls_kernel2">kernel2</option>
                                </param>
                                <!--param name="PLS_Yweights" type="boolean" label="Y weights" help="Y weights represent the coefficients associated with the response variables and are used to model the relationship between predictors and responses in the context of classification. They represent the importance of each response variable in predicting each component. They can be useful if you have multiple response variables."/-->
                                <param name="pls_toplabels" type="integer" value="100" label="Number of toplabels (m/z features) which should be written in tabular output"/>
                                <conditional name="correctness_plot_condition">
                                    <param name="correctness_plot_color" type="select" label="Choose a color scheme for the correctness plot">
                                        <option value="default">Default Colors</option>
                                        <option value="custom">Custom Colors</option>
                                    </param>
                                    <when value="custom">
                                        <param name="true_color" type="color" label="Correct color" value="#f28e2b" help="Color for correctly predicted pixels"/>
                                        <param name="false_color" type="color" label="False color" value="#4e79a7" help="Color for incorrectly predicted pixels"/>
                                    </when>
                                </conditional>
                            </when>
                        </conditional>
                    </when>

                    <when value="OPLS">

                        <conditional name="opls_analysis_cond">
                            <param name="opls_method" type="select" label="Analysis step to perform">
                                <option value="opls_cvapply" selected="True">cvApply</option>
                                <option value="opls_analysis">OPLS-DA analysis</option>
                            </param>

                            <when value="opls_cvapply">
                                <param name="opls_cvcomp" type="text" value="1:2"
                                       label="The number of OPLS-DA components" help="For cvapply multiple values are allowed (e.g. 1,2,3 or 2:5). Minimum is 1.">
                                <expand macro="sanitizer_multiple_digits"/>
                                </param>
                            </when>

                            <when value="opls_analysis">
                                <param name="opls_comp" type="integer" value="5"
                                       label="The optimal number of OPLS-DA components as indicated by cross-validations (minimum is 1)" help="Run cvApply first to optain optimal number of OPLS-DA components"/>
                                <!--param name="xnew" type="boolean" truevalue="TRUE" falsevalue="FALSE" label="Keep new matrix"/-->
                                <param name="opls_scale" type="boolean" truevalue="TRUE" falsevalue="FALSE" label="Data scaling"/>
                                <param name="opls_center" type="boolean" truevalue="TRUE" falsevalue="FALSE" label="Data centering"/>
                                <!--param name="opls_alg" type="select" label="OPLS method">
                                    <option value="opls_nipals" selected="True">nipals</option>
                                    <option value="opls_simpls">simpls</option>
                                    <option value="opls_kernel1">kernel1</option>
                                    <option value="opls_kernel2">kernel2</option>
                                </param-->
                                <!--param name="OPLS_Yweights" type="boolean" label="Y weights" help="Y weights represent the coefficients associated with the response variables and are used to model the relationship between predictors and responses in the context of classification. They represent the importance of each response variable in predicting each component. They can be useful if you have multiple response variables."/-->
                                <param name="opls_toplabels" type="integer" value="100"
                                   label="Number of toplabels (m/z features) which should be written in tabular output"/>
                                <conditional name="correctness_plot_condition">
                                    <param name="correctness_plot_color" type="select" label="Choose a color scheme for the correctness plot">
                                        <option value="default">Default Colors</option>
                                        <option value="custom">Custom Colors</option>
                                    </param>
                                    <when value="custom">
                                        <param name="true_color" type="color" label="Correct color" value="#f28e2b" help="Color for correctly predicted pixels"/>
                                        <param name="false_color" type="color" label="False color" value="#4e79a7" help="Color for incorrectly predicted pixels"/>
                                    </when>
                                </conditional>
                            </when>
                        </conditional>
                    </when>

                    <when value="spatialShrunkenCentroids">
                        <conditional name="ssc_analysis_cond">
                            <param name="ssc_method" type="select" label="Analysis step to perform">
                                <option value="ssc_cvapply" selected="True">cvApply</option>
                                <option value="ssc_analysis">spatial shrunken centroids analysis</option>
                            </param>
                            <when value="ssc_cvapply">
                                  <param name="write_best_params" type="boolean" label="Write out best r and s values" help="Can be used to generate automatic classification workflow"/>
                                  <param name="ssc_cv_accuracy_plot" type="boolean" label="Plot CV accuracy plots on one page (=Yes) or individual pages (=No)"/>
                            </when>
                            <when value="ssc_analysis">
                                <param name="ssc_toplabels" type="integer" value="100"
                                   label="Number of toplabels (m/z features) which should be written in tabular output"/>
                                <conditional name="correctness_plot_condition">
                                    <param name="correctness_plot_color" type="select" label="Choose a color scheme for the correctness plot">
                                        <option value="default">Default Colors</option>
                                        <option value="custom">Custom Colors</option>
                                    </param>
                                    <when value="custom">
                                        <param name="true_color" type="color" label="Correct color" value="#f28e2b" help="Color for correctly predicted pixels"/>
                                        <param name="false_color" type="color" label="False color" value="#4e79a7" help="Color for incorrectly predicted pixels"/>
                                    </when>
                                </conditional>
                            </when>
                        </conditional>
                        <param name="ssc_r" type="text" value="2"
                               label="The spatial neighborhood radius of nearby pixels to consider (r)" help="For cvapply multiple values are allowed (e.g. 0,1,2,3 or 2:5)">
                        <expand macro="sanitizer_multiple_digits"/>
                        </param>
                        <param name="ssc_s" type="text" value="2"
                               label="The sparsity thresholding parameter by which to shrink the t-statistics (s)." help="For cvapply multiple values are allowed (e.g. 0,1,2 or 2:5)">
                        <expand macro="sanitizer_multiple_digits"/>
                        </param>
                        <param name="ssc_kernel_method" type="select" display="radio" label = "The method to use to calculate the spatial smoothing kernels for the embedding. The 'gaussian' method refers to spatially-aware (SA) weights, and 'adaptive' refers to spatially-aware structurally-adaptive (SASA) weights">
                            <option value="gaussian">gaussian</option>
                            <option value="adaptive" selected="True">adaptive</option>
                        </param>
                    </when>
                </conditional>

            </when>

            <when value="prediction">
                <param name="training_result" type="data" format="rdata" label="Result from previous classification training"/>
                <conditional name="classification_type_cond">
                    <param name="classification_type" type="select" label="Which classification method was used">
                	    <option value="PLS_classifier" selected="True" >PLS classifier</option>
                	    <option value="OPLS_classifier">OPLS classifier</option>
                	    <option value="SSC_classifier">SSC classifier</option>
                    </param>
                    <when value="PLS_classifier"/>
                    <when value="OPLS_classifier"/>
                    <when value="SSC_classifier">
                        <param name="predicted_toplabels" type="integer" value="100"
                                   label="Number of toplabels (m/z features) which should be written in tabular output"/>
                    </when>
                </conditional>
                <conditional name="new_y_values_cond">
                    <param name="new_y_values" type="select" label="Load annotations (optional, but allows accuracy calculations)">
                        <option value="no_new_response" selected="True">no</option>
                        <option value="new_response">use annotations</option>
                    </param>
                    <when value="no_new_response"/>
                    <when value="new_response">
                        <param name="new_response_file" type="data" format="tabular" label="Load tabular file with pixel coordinates and the new response"/>
                        <param name="column_new_x" data_ref="new_response_file" label="Column with x values" type="data_column"/>
                        <param name="column_new_y" data_ref="new_response_file" label="Column with y values" type="data_column"/>
                        <param name="column_new_response" data_ref="new_response_file" label="Column with new response values" type="data_column"/>
                        <param name="new_tabular_header" type="boolean" label="Tabular files contain a header line" truevalue="TRUE" falsevalue="FALSE"/>
                        <conditional name="correctness_plot_condition">
                            <param name="correctness_plot_color" type="select" label="Choose a color scheme for the correctness plot">
                                <option value="default">Default Colors</option>
                                <option value="custom">Custom Colors</option>
                            </param>
                            <when value="custom">
                                <param name="true_color" type="color" label="Correct color" value="#f28e2b" help="Color for correctly predicted pixels"/>
                                <param name="false_color" type="color" label="False color" value="#4e79a7" help="Color for incorrectly predicted pixels"/>
                            </when>
                        </conditional>
                    </when>
                </conditional>
            </when>
        </conditional>
        <conditional name="colour_conditional">
	    <param name="colour_type" type="select" label="Choose a colour scheme">
	        <option value="colourpalette" selected="True" >Colour palette</option>
	        <option value="manual_colour">Manual selection</option>
	    </param>
	    <when value="manual_colour">
	       <repeat name="colours" title="Colours for the plots" min="1" max="50">
	       <param name="annotation_color" type="color" label="Colours" value="#ff00ff" help="Numbers of colours should be the same as number of components">
	       <sanitizer>
	           <valid initial="string.letters,string.digits">
	           <add value="#" />
	           </valid>
	       </sanitizer>
	       </param>
	       </repeat>
	    </when>
	    <when value="colourpalette">
	        <param name="palettes" type="select" display="radio" label="Select a colourpalette">
		    <option value="hue_pal()" selected="True">hue</option>
		    <option value="rainbow">rainbow</option>
		    <option value="heat.colors">heat colors</option>
		    <option value="terrain.colors">terrain colors</option>
		    <option value="topo.colors">topo colors</option>
		    <option value="cm.colors">cm colors</option>
	        </param>
	    </when>
        </conditional>

        <param name="output_rdata" type="boolean" label="Results as .RData output" help="Can be used to generate a classification prediction on new data"/>
    </inputs>
    <outputs>
        <data format="pdf" name="classification_images" from_work_dir="classificationpdf.pdf" label = "${tool.name} on ${on_string}: results"/>
        <data format="tabular" name="pixeloutput" label="${tool.name} on ${on_string}: pixels">
            <filter>type_cond['type_method'] == 'training' and type_cond['method_cond']['class_method'] == 'PLS' and type_cond['method_cond']['analysis_cond']['PLS_method'] == 'PLS_analysis' or type_cond['type_method'] == 'training' and type_cond['method_cond']['class_method'] == 'OPLS' and type_cond['method_cond']['opls_analysis_cond']['opls_method'] == 'opls_analysis' or type_cond['type_method'] == 'training' and type_cond['method_cond']['class_method'] == 'spatialShrunkenCentroids' and type_cond['method_cond']['ssc_analysis_cond']['ssc_method'] == 'ssc_analysis' or type_cond['type_method'] == 'prediction'</filter>
        </data>
        <data format="tabular" name="topfeatures" label="${tool.name} on ${on_string}: topFeatures">
            <filter>type_cond['type_method'] == 'training' and type_cond['method_cond']['class_method'] == 'PLS' and type_cond['method_cond']['analysis_cond']['PLS_method'] == 'PLS_analysis' or type_cond['type_method'] == 'training' and type_cond['method_cond']['class_method'] == 'OPLS' and type_cond['method_cond']['opls_analysis_cond']['opls_method'] == 'opls_analysis'</filter>
        </data>
        <data format="tabular" name="scoresoutput" label="${tool.name} on ${on_string}: component scores">
            <filter>type_cond['type_method'] == 'training' and type_cond['method_cond']['class_method'] == 'PLS' and type_cond['method_cond']['analysis_cond']['PLS_method'] == 'PLS_analysis' or type_cond['type_method'] == 'training' and type_cond['method_cond']['class_method'] == 'OPLS' and type_cond['method_cond']['opls_analysis_cond']['opls_method'] == 'opls_analysis'</filter>
        </data>
        <data format="txt" name="best_r" label="${tool.name} on ${on_string}:best r">
        <filter>type_cond['type_method'] == 'training' and type_cond['method_cond']['class_method'] == 'spatialShrunkenCentroids' and type_cond['method_cond']['ssc_analysis_cond']['ssc_method'] == 'ssc_cvapply' and type_cond['method_cond']['ssc_analysis_cond']['write_best_params']</filter>
        </data>
        <data format="txt" name="best_s" label="${tool.name} on ${on_string}:best s">
        <filter>type_cond['type_method'] == 'training' and type_cond['method_cond']['class_method'] == 'spatialShrunkenCentroids' and type_cond['method_cond']['ssc_analysis_cond']['ssc_method'] == 'ssc_cvapply' and type_cond['method_cond']['ssc_analysis_cond']['write_best_params']</filter>
        </data>
        <data format="rdata" name="classification_rdata" label="${tool.name} on ${on_string}: results.RData">
        <filter>output_rdata</filter>
        </data>
    </outputs>
    <tests>
        <test expect_num_outputs="1">
            <param name="infile" value="testfile_squares.rdata" ftype="rdata"/>
            <conditional name="type_cond">
                <param name="type_method" value="training"/>
                <param name="annotation_file" value= "pixel_annotation_file1.tabular" ftype="tabular"/>
                <param name="column_x" value="1"/>
                <param name="column_y" value="2"/>
                <param name="column_response" value="4"/>
                <param name="column_fold" value="3"/>
                <param name="tabular_header" value="False"/>
                <conditional name="method_cond">
                    <param name="class_method" value="PLS"/>
                    <conditional name="analysis_cond">
                        <param name="PLS_method" value="cvapply"/>
                        <param name="plscv_comp" value="2:4"/>
                    </conditional>
                </conditional>
            </conditional>
            <output name="classification_images" file="test1.pdf" compare="sim_size" delta="2000"/>
        </test>

        <test expect_num_outputs="5">
            <param name="infile" value="testfile_squares.rdata" ftype="rdata"/>
            <conditional name="type_cond">
                <param name="type_method" value="training"/>
                <param name="annotation_file" value= "pixel_annotation_file1.tabular" ftype="tabular"/>
                <param name="column_x" value="1"/>
                <param name="column_y" value="2"/>
                <param name="column_response" value="4"/>
                <param name="tabular_header" value="False"/>
                <conditional name="method_cond">
                    <param name="class_method" value="PLS"/>
                    <conditional name="analysis_cond">
                        <param name="PLS_method" value="PLS_analysis"/>
                        <param name="pls_comp" value="2"/>
                        <param name="pls_scale" value="TRUE"/>
                        <param name="PLS_Yweights" value="TRUE"/>
                        <!--param name="pls_toplabels" value="100"/-->
                    </conditional>
                </conditional>
            </conditional>
            <param name="output_rdata" value="True"/>
            <output name="coefficients">
                <assert_contents>
                    <has_text text="900.004699707031"/>
                    <has_text text="962.870727539062"/>
                    <has_text text="999.606872558594"/>
                </assert_contents>
            </output>
            <output name="loadings_weights">
                <assert_contents>
                    <has_text text="900.076354980469"/>
                    <has_text text="950.495910644531"/>
                    <has_text text="989.024536132812"/>
                </assert_contents>
            </output>
            <output name="pixeloutput" file="pixels_test2.tabular"/>
            <output name="classification_images" file="test2.pdf" compare="sim_size"/>
            <output name="classification_rdata" file="test2.rdata" compare="sim_size"/>
        </test>

        <test expect_num_outputs="1">
            <param name="infile" value="testfile_squares.rdata" ftype="rdata"/>
            <conditional name="type_cond">
                <param name="type_method" value="training"/>
                <param name="annotation_file" value= "random_factors.tabular" ftype="tabular"/>
                <param name="column_x" value="1"/>
                <param name="column_y" value="2"/>
                <param name="column_response" value="4"/>
                <param name="column_fold" value="3"/>
                <param name="tabular_header" value="False"/>
                <conditional name="method_cond">
                    <param name="class_method" value="OPLS"/>
                    <conditional name="opls_analysis_cond">
                        <param name="opls_method" value="opls_cvapply"/>
                        <param name="opls_cvcomp" value="1:2"/>
                    </conditional>
                </conditional>
            </conditional>
            <output name="classification_images" file="test3.pdf" compare="sim_size"/>
        </test>

        <test expect_num_outputs="5">
            <param name="infile" value="testfile_squares.rdata" ftype="rdata"/>
            <conditional name="type_cond">
                <param name="type_method" value="training"/>
                <param name="annotation_file" value= "random_factors.tabular" ftype="tabular"/>
                <param name="column_x" value="1"/>
                <param name="column_y" value="2"/>
                <param name="column_response" value="4"/>
                <param name="tabular_header" value="False"/>
                <conditional name="method_cond">
                    <param name="class_method" value="OPLS"/>
                    <conditional name="opls_analysis_cond">
                        <param name="opls_method" value="opls_analysis"/>
                        <param name="opls_comp" value="3"/>
                        <param name="opls_scale" value="FALSE"/>
                        <param name="PLS_Yweights" value="FALSE"/>
                    </conditional>
                </conditional>
            </conditional>
            <param name="output_rdata" value="True"/>
            <output name="pixeloutput" file="pixels_test4.tabular"/>
            <output name="coefficients">
                <assert_contents>
                    <has_text text="900.148010253906"/>
                    <has_text text="974.132446289062"/>
                    <has_text text="999.908935546875"/>
                </assert_contents>
            </output>
            <output name="loadings_weights">
                <assert_contents>
                    <has_text text="901.581848144531"/>
                    <has_text text="939.189086914062"/>
                    <has_text text="984.185363769531"/>
                </assert_contents>
            </output>
            <output name="classification_images" file="test4.pdf" compare="sim_size"/>
            <output name="classification_rdata" file="test4.rdata" compare="sim_size"/>
        </test>

        <test expect_num_outputs="3">
            <param name="infile" value="testfile_squares.rdata" ftype="rdata"/>
            <conditional name="type_cond">
                <param name="type_method" value="training"/>
                <param name="annotation_file" value= "pixel_annotation_file1.tabular" ftype="tabular"/>
                <param name="column_x" value="1"/>
                <param name="column_y" value="2"/>
                <param name="column_response" value="3"/>
                <param name="column_fold" value="4"/>
                <param name="tabular_header" value="False"/>
                <conditional name="method_cond">
                    <param name="class_method" value="spatialShrunkenCentroids"/>
                    <conditional name="ssc_analysis_cond">
                        <param name="ssc_method" value="ssc_cvapply"/>
                        <param name="ssc_r" value="1:2"/>
                        <param name="ssc_s" value="2:3"/>
                        <param name="ssc_kernel_method" value="adaptive"/>
                        <param name="write_best_params" value="TRUE"/>
                    </conditional>
                </conditional>
            </conditional>
            <output name="classification_images" file="test5.pdf" compare="sim_size"/>
            <output name="best_r" file="best_r_test5.txt"/>
            <output name="best_s" file="best_s_test5.txt"/>
        </test>

        <test expect_num_outputs="4">
            <param name="infile" value="testfile_squares.rdata" ftype="rdata"/>
            <conditional name="type_cond">
                <param name="type_method" value="training"/>
                <param name="annotation_file" value= "random_factors.tabular" ftype="tabular"/>
                <param name="column_x" value="1"/>
                <param name="column_y" value="2"/>
                <param name="column_response" value="4"/>
                <conditional name="method_cond">
                    <param name="class_method" value="spatialShrunkenCentroids"/>
                    <conditional name="ssc_analysis_cond">
                        <param name="ssc_method" value="ssc_analysis"/>
                        <param name="ssc_toplabels" value="20"/>
                     </conditional>
                    <param name="ssc_r" value="2"/>
                    <param name="ssc_s" value="2"/>
                    <param name="ssc_kernel_method" value="adaptive"/>
                </conditional>
            </conditional>
            <param name="output_rdata" value="True"/>
            <output name="mzfeatures" file="features_test6.tabular"/>
            <output name="pixeloutput" file="pixels_test6.tabular"/>
            <output name="classification_images" file="test6.pdf" compare="sim_size"/>
            <output name="classification_rdata" file="test6.rdata" compare="sim_size" delta="15000"/>
        </test>

        <test expect_num_outputs="5">
            <param name="infile" value="testfile_squares.rdata" ftype="rdata"/>
            <conditional name="type_cond">
                <param name="type_method" value="prediction"/>
                <param name="type_method" value="prediction"/>
                <param name="training_result" value="test2.rdata" ftype="rdata"/>
                <param name="classification_type" value="PLS_classifier"/>
                <conditional name="new_y_values_cond">
                    <param name="new_y_values" value="new_response"/>
                        <param name="new_response_file" value="pixel_annotation_file1.tabular" ftype="tabular"/>
                        <param name="column_new_x" value="1"/>
                        <param name="column_new_y" value="2"/>
                        <param name="column_new_response" value="4"/>
                        <param name="new_tabular_header" value="False"/>
                </conditional>
            </conditional>
            <param name="output_rdata" value="True"/>
            <output name="coefficients" file="coefficients_test7.tabular"/>
            <output name="loadings_weights" file="loadings_and_weights_test7.tabular"/>
            <output name="pixeloutput" file="pixels_test7.tabular"/>
            <output name="classification_images" file="test7.pdf" compare="sim_size"/>
            <output name="classification_rdata" file="test7.rdata" compare="sim_size" />
        </test>
    </tests>
    <help>
        <![CDATA[


@CARDINAL_DESCRIPTION@

-----

This tool provides three different Cardinal functions for supervised classification of mass-spectrometry imaging data.

@MSIDATA_INPUT_DESCRIPTION@
            - NA intensities are not allowed
            - duplicated coordinates will be removed

- For training: tabular file with condition and fold for each pixel: Two columns for pixel coordinates (x and y values); one column with the condition for the pixel, which will be used for classification; for the cross validation (cvapply) another column with a fold is necessary, each fold must contain pixels of all response groups and is used for cross validation. Condition and fold columns are treated as factor to perform discriminant analysis (also when numeric values are provided).

    ::

     x_coord     y_coord      condition    fold
        1            1           A          f1
        2            1           A          f2
        3            1           A          f3
        1            2           B          f1
        2            2           B          f2
        3            2           B          f3
       ...
       ...


- For prediction: RData output from previous classification run is needed as input, optionally new response values can be loaded with a tabular file containing x values, y values and the response


**Options**

- PLS-DA: partial least square discriminant analysis
- O-PLS-DA: Orthogonal partial least squares discriminant analysis
- Spatial shrunken centroids (more details in `Bemis et al. <https://doi.org/10.1074/mcp.O115.053918>`_)
- training and prediction

    - training can be done with cvapply that uses cross validation to find the best value for s, this requires not only a condition for each spectrum but also a fold (each fold should contain spectra of all conditions)
    - training with the best value for r and s gives the top m/z features for each condition and the predicted classification group for each spectrum
    - training result can be saved as RData file that can be reused for prediction of further samples
    - prediction can calculate accuracies when the annotations are known and provided


.. image:: $PATH_TO_IMAGES/classification_overview.png
   :width: 1000
   :height: 465



**Tips**

- The classification function will only run on files with valid intensity values (NA are not allowed)
- Only a single input file is accepted, several files have to be combined previously, for example with the MSI combine tool.


**Output**

- Pdf with the heatmaps and plots for the classification
- Tabular file with information on m/z features and pixels: toplabels/classes
- Optional: RData output that can be used to predict new data or to explore the results more deeply with the Cardinal package in R

        ]]>
    </help>
    <expand macro="citations"/>
</tool>

